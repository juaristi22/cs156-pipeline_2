\section{Introduction}
\label{sec:introduction}

% Introduction covering:

\subsection{Motivation}

Microsimulation models are essential tools for policy analysis, enabling researchers to estimate the distributional impacts of tax and benefit reforms across heterogeneous populations. However, these models require comprehensive microdata representing both demographic and economic characteristics. Such data often do not coexist in a single survey. For example, in the context of supporting microeconomic analysis in the United States, the Current Population Survey (CPS) provides large, representative samples with detailed income and demographic information, making it ideal for policy microsimulation, yet it lacks any measure of household wealth. The Survey of Consumer Finances (SCF), meanwhile, offers detailed wealth data but with a sample size roughly thirteen times smaller. This fragmentation limits researchers' ability to analyze how policies interact with the full joint distribution of income and wealth.

Full variable imputation addresses this gap by transferring information from a ``donor'' survey (the SCF) onto a ``receiver'' survey (the CPS), enabling analyses that neither dataset could support alone. Recent work by \citet{juaristi2025microimpute} benchmarked traditional imputation methods for this SCF-to-CPS wealth transfer problem, finding that Quantile Regression Forests (QRF) outperformed conventional approaches, achieving 20.5\% lower quantile loss than OLS regression, 14.8\% lower than hot-deck matching and 6\% lower than Quantile regression. QRF's advantage stems from its ability to model entire conditional distributions rather than merely conditional means, preserving the heavy tails and skewness characteristic of wealth data.

Nonetheless, QRF faces challenges, particularly as limited data at extreme quantiles may affect performance at the tails of distributions, which are often crucial for policy analysis. After benchmarking traditional methods \citet{juaristi2025microimpute} identified comparative studies against deep learning models as a valuable future research direction, with the hope that emerging techniques can better capture complex distributional features. This motivates the present work. Deep generative models offer a fundamentally different approach to distribution learning, introducing flexibility in their modeling of complex, non-linear distributions. Normalizing flows \citep{dinh2016density} start with a simple distribution (like a Gaussian) and learn a series of transformations that reshape it into the complex target distribution; because each transformation is reversible, the model can both generate new samples and compute exact probabilities. Mixture Density Networks \citep{bishop1994mixture} represent the target as a weighted combination of multiple Gaussian components, allowing them to capture multimodality. Diffusion models, as implemented in TabSyn \citep{zhang2023mixed}, work by learning to gradually remove noise from corrupted data, capturing the underlying data structure through this denoising process. These architectures have demonstrated state-of-the-art performance in density estimation and synthetic data generation, suggesting potential for imputation tasks where preserving distributional accuracy across donor and receiver datasets becomes crucial.

This paper investigates whether deep generative models can match or exceed QRF's performance for wealth imputation, and under what conditions each approach excels. In addition to methodological comparison and improvement, success in such an imputation task has direct policy relevance, as accurate wealth imputation enables more precise analysis of wealth taxes, and the distributional consequences of fiscal policy across the income-wealth spectrum. Furthermore, fragmented data sources are common in many fields, which can hinder many different lines of research. Robust imputation methods hence have the potential to enhance the quality of datasets used across various domains where data fragmentation is common, expanding data enhancement practices beyond social science research.

\subsection{Problem Statement}

The task addressed in this paper is a form of statistical matching (also called data fusion or full variable imputation), formally defined as the integration of two data sources referring to the same target population \citep{d2015statistical}. Let $\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^{n_D}$ denote the \textit{donor} dataset (SCF), where $\mathbf{x}_i \in \mathbb{R}^p$ is a vector of $p$ predictor variables and $y_i \in \mathbb{R}$ is the target variable (net worth). Let $\mathcal{R} = \{\mathbf{x}_j\}_{j=1}^{n_R}$ denote the \textit{receiver} dataset (CPS), which contains the same predictors but lacks the target variable. The predictors $\mathbf{X}$ are observed in both surveys, while net worth $Y$ is observed only in the donor.

The goal is to impute values $\hat{y}_j$ for each receiver observation $\mathbf{x}_j \in \mathcal{R}$. This requires learning the conditional distribution $P(Y \mid \mathbf{X})$ from the donor data and using it to generate plausible values for the receiver. Unlike point prediction, which estimates only $\mathbb{E}[Y \mid \mathbf{X}]$, distributional imputation aims to preserve the full conditional distribution, including its variance, skewness, and tail behavior. This is essential for policy analysis, where outcomes often depend on distributional features rather than point estimates alone.

An important assumption underlying statistical matching is that of conditional independence. Given the shared predictors $\mathbf{X}$, the target variable $Y$ is independent of survey membership. Formally, $P(Y \mid \mathbf{X}, S=\text{SCF}) = P(Y \mid \mathbf{X}, S=\text{CPS})$, where $S$ indicates the survey. This assumption is plausible when the shared predictors are sufficiently informative about net worth, such that no survey-specific factors influence wealth beyond what the predictors already capture. Violations of this assumption can lead to biased imputations, as the learned conditional distribution may not generalize well from the donor to the receiver. This makes careful selection of predictor variables and validation of imputation performance critical. Limitations on data availability lead us to using data from different years (2022 SCF and 2023 CPS), which may introduce temporal shifts in distributions. We assume that such shifts are minimal and that model performance and reliability will be transferable to more aligned datasets.

\subsection{Contributions}

This paper makes two important contributions:

\begin{enumerate}
    \item \textbf{Adaptation of generative models for cross-dataset imputation.} We adapt deep generative models, which were originally designed for density estimation and synthetic data generation, to the statistical matching setting, where imputation must be conditioned on a receiver dataset distinct from the training data. This requires architectural modifications, particularly for TabSyn, which we extend to condition its diffusion sampling on receiver observations rather than only generating from the learned donor distribution.

    \item \textbf{Benchmarking of deep generative models for imputation.} We evaluate three deep learning architectures---RealNVP (normalizing flows), Mixture Density Networks, and TabSyn (diffusion-based)---for the task of wealth imputation, benchmarking them against Quantile Regression Forests established as the state-of-the-art in prior work.
\end{enumerate}

\subsection{Paper Organization}

The remainder of this paper is organized as follows. Section~\ref{sec:data} describes the SCF and CPS datasets, the preprocessing steps required to harmonize them, and the data-splitting strategy used for model evaluation. Section~\ref{sec:models} presents the mathematical foundations and adaptations of each imputation method: RealNVP, Mixture Density Networks, TabSyn, and the QRF baseline. Section~\ref{sec:results} reports the cross-validation and distributional accuracy results, comparing model performance across evaluation metrics. Section~\ref{sec:conclusion} summarizes our findings and discusses implications for applied researchers. The appendix contains implementation details and the complete code used for this analysis.
